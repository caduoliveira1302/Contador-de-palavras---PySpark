{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from googletrans import Translator\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import explode, col, trim, rtrim, ltrim\n",
    "from pyspark.sql.functions import regexp_replace, regexp_extract\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import re\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(txt_path):\n",
    "    #pyspark session\n",
    "    spark = SparkSession.builder.appName(\"PySpark-ContandoPalavras\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    #txt doc\n",
    "    df = spark.read.text(f\"{txt_path}\")\n",
    "\n",
    "    #spliting the df by space \" \" \n",
    "    df = df.select(\n",
    "    split(df['value'], ' ').alias('words'))\n",
    "\n",
    "    #removing stopwords\n",
    "    stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words2\")\n",
    "    df = stopwords_remover.transform(df)\n",
    "    df = df.drop(\"words\")\n",
    "\n",
    "    #extracting words from the lists\n",
    "    df = df.select(\n",
    "    explode(col(\"words2\")).alias(\"words3\"))\n",
    "    \n",
    "    # Removing the NULLs\n",
    "    df = df.where(\n",
    "        col(\"words3\") != \"\")\n",
    "    \n",
    "    #removing punctuation\n",
    "    df = df.select(\n",
    "    regexp_extract(\n",
    "    col('words3'),  #cleaning words2 column\n",
    "    '[A-z]+',       #selecting all the words\n",
    "    0).alias('words4'))\n",
    "\n",
    "    #every word to lower case\n",
    "    df = df.select(\n",
    "    lower(\n",
    "    col('words4')\n",
    "    ).alias('words5'))\n",
    "\n",
    "    #FIRST COUNT#\n",
    "    df_counted = df.groupBy(\n",
    "        col(\"words5\"),\n",
    "    ).count()\n",
    "\n",
    "    #RETAKING\n",
    "    df2 = df.select(\n",
    "        split(\n",
    "            col(\"words5\"),\n",
    "            \" \"\n",
    "        ).alias(\"word6\"))\n",
    "    \n",
    "    #removing stopwords - step2\n",
    "    stopwords_remover2 = StopWordsRemover(\n",
    "    inputCol=\"word6\",\n",
    "    outputCol=\"words7\")\n",
    "    df2 = stopwords_remover2.transform(df2)\n",
    "\n",
    "    #removing nulls - step2\n",
    "    df2 = df2.select(\n",
    "        (col(\"words7\")[0]).alias(\"words8\"))\n",
    "\n",
    "    df2 = df2.where(\n",
    "    col(\"words8\") != \"null\")\n",
    "\n",
    "    df2 = df2.where(\n",
    "        col(\"words8\") != \"\")\n",
    "    \n",
    "    #FINAL COUNT#\n",
    "    df_counted2 = df2.groupby(\n",
    "    col(\"words8\")\n",
    "    ).count()\n",
    "\n",
    "    df_counted2 = df_counted2.orderBy(desc(\"count\")).toPandas()\n",
    "    \n",
    "    return df_counted2\n",
    "    # return df_counted2.orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#folder path\n",
    "folder_path = 'C:/Users/cedua/CDIA - PUCSP/PROJETO PySpark - SAVINO/Contador-de-palavras---PySpark/data'\n",
    "\n",
    "#iterating the txt files only\n",
    "for txt_file in glob.glob(os.path.join(folder_path, '*.txt')):\n",
    "    df_pandas = count_words(txt_file)\n",
    "    df_pandas.to_csv(f'{txt_file}.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
