{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cedua\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import explode, col, trim, rtrim, ltrim\n",
    "from pyspark.sql.functions import regexp_replace, regexp_extract\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserScreenName</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedded_text</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Image link</th>\n",
       "      <th>Tweet URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kamii</td>\n",
       "      <td>@kami_whey</td>\n",
       "      <td>2022-06-15T22:28:20.000Z</td>\n",
       "      <td>kamii\\n@kami_whey\\n¬∑\\nJun 15, 2022</td>\n",
       "      <td>i will not give context, i just find this imag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>['https://pbs.twimg.com/media/FVU7ZmGWAAIqepU?...</td>\n",
       "      <td>https://twitter.com/kami_whey/status/153720035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tia feri.</td>\n",
       "      <td>@feristhii</td>\n",
       "      <td>2022-06-15T21:29:34.000Z</td>\n",
       "      <td>tia feri.\\n@feristhii\\n¬∑\\nJun 15, 2022</td>\n",
       "      <td>Apenas um treino usando uma gostosa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>869</td>\n",
       "      <td>['https://pbs.twimg.com/media/FVUuIaeWUAA13vp?...</td>\n",
       "      <td>https://twitter.com/feristhii/status/153718557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monty Riches</td>\n",
       "      <td>@MontyRiches</td>\n",
       "      <td>2022-06-15T22:34:27.000Z</td>\n",
       "      <td>Monty Riches\\n@MontyRiches\\n¬∑\\nJun 15, 2022</td>\n",
       "      <td>MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...</td>\n",
       "      <td>üö® ü¶ß üö® üí™ ü¶ç</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>['https://pbs.twimg.com/media/FVU8-5cXsAEsOqc?...</td>\n",
       "      <td>https://twitter.com/MontyRiches/status/1537201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Walk Like an Egyptian Bot</td>\n",
       "      <td>@egyptian_bot</td>\n",
       "      <td>2022-06-15T22:10:49.000Z</td>\n",
       "      <td>Walk Like an Egyptian Bot\\n@egyptian_bot\\n¬∑\\nJ...</td>\n",
       "      <td>Foreign types with the hookah pipes say ay oh ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/egyptian_bot/status/153719...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thomas the gain</td>\n",
       "      <td>@thomasphall</td>\n",
       "      <td>2022-06-15T20:49:42.000Z</td>\n",
       "      <td>thomas the gain\\n@thomasphall\\n¬∑\\nJun 15, 2022</td>\n",
       "      <td>I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...</td>\n",
       "      <td>üöÇ üòÇ</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/thomasphall/status/1537175...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              UserScreenName       UserName                 Timestamp  \\\n",
       "0                      kamii     @kami_whey  2022-06-15T22:28:20.000Z   \n",
       "1                  tia feri.     @feristhii  2022-06-15T21:29:34.000Z   \n",
       "2               Monty Riches   @MontyRiches  2022-06-15T22:34:27.000Z   \n",
       "3  Walk Like an Egyptian Bot  @egyptian_bot  2022-06-15T22:10:49.000Z   \n",
       "4            thomas the gain   @thomasphall  2022-06-15T20:49:42.000Z   \n",
       "\n",
       "                                                Text  \\\n",
       "0                 kamii\\n@kami_whey\\n¬∑\\nJun 15, 2022   \n",
       "1             tia feri.\\n@feristhii\\n¬∑\\nJun 15, 2022   \n",
       "2        Monty Riches\\n@MontyRiches\\n¬∑\\nJun 15, 2022   \n",
       "3  Walk Like an Egyptian Bot\\n@egyptian_bot\\n¬∑\\nJ...   \n",
       "4     thomas the gain\\n@thomasphall\\n¬∑\\nJun 15, 2022   \n",
       "\n",
       "                                       Embedded_text     Emojis Comments  \\\n",
       "0  i will not give context, i just find this imag...        NaN        1   \n",
       "1                Apenas um treino usando uma gostosa        NaN        3   \n",
       "2  MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...  üö® ü¶ß üö® üí™ ü¶ç        4   \n",
       "3  Foreign types with the hookah pipes say ay oh ...        NaN      NaN   \n",
       "4  I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...        üöÇ üòÇ        2   \n",
       "\n",
       "  Likes Retweets                                         Image link  \\\n",
       "0   NaN        3  ['https://pbs.twimg.com/media/FVU7ZmGWAAIqepU?...   \n",
       "1    58      869  ['https://pbs.twimg.com/media/FVUuIaeWUAA13vp?...   \n",
       "2     3       19  ['https://pbs.twimg.com/media/FVU8-5cXsAEsOqc?...   \n",
       "3   NaN      NaN                                                 []   \n",
       "4   NaN      NaN                                                 []   \n",
       "\n",
       "                                           Tweet URL  \n",
       "0  https://twitter.com/kami_whey/status/153720035...  \n",
       "1  https://twitter.com/feristhii/status/153718557...  \n",
       "2  https://twitter.com/MontyRiches/status/1537201...  \n",
       "3  https://twitter.com/egyptian_bot/status/153719...  \n",
       "4  https://twitter.com/thomasphall/status/1537175...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter = pd.read_csv('C:\\\\Users\\\\cedua\\\\CDIA - PUCSP\\\\PROJETO PySpark - SAVINO\\\\Contador-de-palavras---PySpark\\\\collecting_data\\\\Twitter\\\\twitter_whey_V3.csv')\n",
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i will not give context, i just find this imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apenas um treino usando uma gostosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Foreign types with the hookah pipes say ay oh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>treino assim pra quem n√£o sabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414</th>\n",
       "      <td>FELLOW GAYMERS RISE UP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8415</th>\n",
       "      <td>Shit is about to get incredibly annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>O TREINO INOVADOR DO CORINTHIANS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>Calories in Egg whites Vs Whey Protein.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8418 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Embedded_text\n",
       "0     i will not give context, i just find this imag...\n",
       "1                   Apenas um treino usando uma gostosa\n",
       "2     MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...\n",
       "3     Foreign types with the hookah pipes say ay oh ...\n",
       "4     I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...\n",
       "...                                                 ...\n",
       "8413                     treino assim pra quem n√£o sabe\n",
       "8414                             FELLOW GAYMERS RISE UP\n",
       "8415           Shit is about to get incredibly annoying\n",
       "8416                   O TREINO INOVADOR DO CORINTHIANS\n",
       "8417            Calories in Egg whites Vs Whey Protein.\n",
       "\n",
       "[8418 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ONLY THE TEXT\n",
    "df_twitter_text = df_twitter[['Embedded_text']]\n",
    "df_twitter_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cedua\\AppData\\Local\\Temp\\ipykernel_6936\\2608503998.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_twitter_text['lang'] = df_twitter_text['Embedded_text'].apply(detect_language)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedded_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i will not give context, i just find this imag...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apenas um treino usando uma gostosa</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Foreign types with the hookah pipes say ay oh ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Embedded_text lang\n",
       "0  i will not give context, i just find this imag...   en\n",
       "1                Apenas um treino usando uma gostosa   pt\n",
       "2  MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...   en\n",
       "3  Foreign types with the hookah pipes say ay oh ...   en\n",
       "4  I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...   en"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATING A NEW FEATURE TO INDENTIFY THE LANGUAGE OF THE TEXT\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_twitter_text['lang'] = df_twitter_text['Embedded_text'].apply(detect_language)\n",
    "df_twitter_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE -- > (8418, 2)\n",
      "HOW MANY LANGUAGES -- > 31\n",
      "{'no', 'so', 'ja', 'th', 'et', 'ar', 'de', 'cs', 'nl', 'tl', 'ca', 'en', 'sv', 'cy', 'lv', 'vi', 'hr', 'tr', 'es', 'ro', 'sk', 'id', 'pt', 'af', 'fr', 'fi', 'sl', 'sw', 'it', 'hu', 'da'}\n"
     ]
    }
   ],
   "source": [
    "#HOW MANY LANGUAGES?\n",
    "print(f\"SHAPE -- > {df_twitter_text.shape}\")\n",
    "print(f\"HOW MANY LANGUAGES -- > {len(set(df_twitter_text['lang']))}\")\n",
    "print(set(df_twitter_text['lang']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedded_text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i will not give context, i just find this imag...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apenas um treino usando uma gostosa</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Foreign types with the hookah pipes say ay oh ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Embedded_text lang\n",
       "0  i will not give context, i just find this imag...   en\n",
       "1                Apenas um treino usando uma gostosa   pt\n",
       "2  MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...   en\n",
       "3  Foreign types with the hookah pipes say ay oh ...   en\n",
       "4  I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...   en"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FILTERING ENGLISH AND PORTUGUESE\n",
    "df_twitter_text = df_twitter_text.loc[df_twitter_text['lang'].isin(['en', 'pt'])]\n",
    "df_twitter_text.shape\n",
    "df_twitter_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARATING BETWEEN en AND pt TO TRANSLATE en\n",
    "df_twitter_text_en = df_twitter_text[df_twitter_text['lang']=='en'].set_index('lang')\n",
    "df_twitter_text_pt = df_twitter_text[df_twitter_text['lang']=='pt'].set_index('lang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedded_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>i will not give context, i just find this imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>Foreign types with the hookah pipes say ay oh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>smelling my brother's bottle of whey protein p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>who up soundin their fury rn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>Working hard on my crossfit.\\n#CatsOfTwitter #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>Change your life. \\n\\nAnyone can do it. Start ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>Shit is about to get incredibly annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>Calories in Egg whites Vs Whey Protein.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4996 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Embedded_text\n",
       "lang                                                   \n",
       "en    i will not give context, i just find this imag...\n",
       "en    MONTY'S APE WATCH  Mega \"UNDER 10 $SOL\"  Editi...\n",
       "en    Foreign types with the hookah pipes say ay oh ...\n",
       "en    I use to have my autocorrect change ‚Äúway‚Äù to ‚Äú...\n",
       "en    smelling my brother's bottle of whey protein p...\n",
       "...                                                 ...\n",
       "en                         who up soundin their fury rn\n",
       "en    Working hard on my crossfit.\\n#CatsOfTwitter #...\n",
       "en    Change your life. \\n\\nAnyone can do it. Start ...\n",
       "en             Shit is about to get incredibly annoying\n",
       "en              Calories in Egg whites Vs Whey Protein.\n",
       "\n",
       "[4996 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedded_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lang</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>Apenas um treino usando uma gostosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>Tinha mais gente no treino que no jogo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>saudade do crossfit dms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>Hoje eu n√£o acabei o treino foi ele quem acabo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>| Que fofura! \\n\\nJaqueline e Murilo levaram ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>escuta kpop no treino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>#eleuthero\\n#suplementos\\n#sistemarespirat√≥rio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>VEJA: Rodolffo (BBB 21) chama aten√ß√£o por fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>treino assim pra quem n√£o sabe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>O TREINO INOVADOR DO CORINTHIANS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2665 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Embedded_text\n",
       "lang                                                   \n",
       "pt                  Apenas um treino usando uma gostosa\n",
       "pt              Tinha mais gente no treino que no jogo.\n",
       "pt                              saudade do crossfit dms\n",
       "pt    Hoje eu n√£o acabei o treino foi ele quem acabo...\n",
       "pt     | Que fofura! \\n\\nJaqueline e Murilo levaram ...\n",
       "...                                                 ...\n",
       "pt                                escuta kpop no treino\n",
       "pt    #eleuthero\\n#suplementos\\n#sistemarespirat√≥rio...\n",
       "pt     VEJA: Rodolffo (BBB 21) chama aten√ß√£o por fal...\n",
       "pt                       treino assim pra quem n√£o sabe\n",
       "pt                     O TREINO INOVADOR DO CORINTHIANS\n",
       "\n",
       "[2665 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_twitter_text_en)\n",
    "display(df_twitter_text_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING TO CSV --> TXT --> WORD COUNT PYSPARK \n",
    "df_twitter_text_pt.to_csv('C:\\\\Users\\\\cedua\\\\CDIA - PUCSP\\\\PROJETO PySpark - SAVINO\\\\Contador-de-palavras---PySpark\\\\collecting_data/twitter_pt_data.csv', index=False)\n",
    "df_twitter_text_en.to_csv('C:\\\\Users\\\\cedua\\\\CDIA - PUCSP\\\\PROJETO PySpark - SAVINO\\\\Contador-de-palavras---PySpark\\\\collecting_data/twitter_en_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_twitter_data_PT(txt_path):\n",
    "    #pyspark session\n",
    "    spark = SparkSession.builder.appName(\"PySpark-LimpandoTwitterData\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    #txt doc\n",
    "    df = spark.read.text(f\"{txt_path}\")\n",
    "\n",
    "    #spliting the df by space \" \" \n",
    "    df = df.select(\n",
    "    split(df.value, ' ').alias('words'))\n",
    "\n",
    "    #extracting words from the lists\n",
    "    df = df.select(\n",
    "    explode(col(\"words\")).alias(\"words3\"))\n",
    "    \n",
    "    #every word to lower case\n",
    "    df = df.select(\n",
    "    lower(\n",
    "    col('words3')\n",
    "    ).alias('words4'))\n",
    "\n",
    "    #removing punctuation\n",
    "    punc_rem = r\"[\\|\\-\\:\\!\\\"\\?\\.,]\"\n",
    "    https_rem = r\"(http|https)://[^\\s]*\"\n",
    "    pra_rem = r\"pra\"\n",
    "    √©_rem = r\"√©(?!([√°√©√≠√≥√∫√£√µ]))\"\n",
    "\n",
    "    df = df.withColumn(\"words5\", regexp_replace(\"words4\", punc_rem, \"\"))\n",
    "    df = df.withColumn(\"words4\", regexp_replace(\"words5\", √©_rem, \"\"))\n",
    "    df = df.withColumn(\"words44\", regexp_replace(\"words4\", pra_rem, \"\"))\n",
    "    df = df.withColumn(\"words7\", regexp_replace(\"words44\", https_rem, \"\"))\n",
    "    \n",
    "    # Removing the NULLs\n",
    "    df = df.where(\n",
    "        col(\"words7\") != \"\")\n",
    "\n",
    "    #FIRST COUNT#\n",
    "    df_counted = df.groupBy(\n",
    "        col(\"words7\"),\n",
    "    ).count()\n",
    "\n",
    "    #RETAKING\n",
    "    df2 = df.select(\n",
    "        split(\n",
    "            col(\"words7\"),\n",
    "            \" \"\n",
    "        ).alias(\"word8\"))\n",
    "    \n",
    "    #removing stopwords - portuguese\n",
    "    stopwords_remover = StopWordsRemover(inputCol=\"word8\", outputCol=\"words9\",   \n",
    "                                            stopWords=StopWordsRemover.loadDefaultStopWords(\"portuguese\"))\n",
    "    df2 = stopwords_remover.transform(df2)\n",
    "    df2 = df2.drop(\"word8\")\n",
    "\n",
    "    #removing nulls - step2\n",
    "    df2 = df2.select(\n",
    "        (col(\"words9\")[0]).alias(\"twitter_text_data_PT\")) #LAST EDIT COL\n",
    "\n",
    "    df2 = df2.where(\n",
    "    col(\"twitter_text_data_PT\") != \"null\")\n",
    "\n",
    "    df2 = df2.where(\n",
    "        col(\"twitter_text_data_PT\") != \"\")\n",
    "    \n",
    "    #FINAL COUNT#\n",
    "    df_counted2 = df2.groupby(\n",
    "    col(\"twitter_text_data_PT\")\n",
    "    ).count()\n",
    "\n",
    "    df_counted2 = df_counted2.orderBy(desc(\"count\")).toPandas()\n",
    "    \n",
    "    return df_counted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_twitter_data_EN(txt_path):\n",
    "    #pyspark session\n",
    "    spark = SparkSession.builder.appName(\"PySpark-LimpandoTwitterData\").getOrCreate()\n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    #txt doc\n",
    "    df = spark.read.text(f\"{txt_path}\")\n",
    "\n",
    "    #spliting the df by space \" \" \n",
    "    df = df.select(\n",
    "    split(df['value'], ' ').alias('words'))\n",
    "    \n",
    "    #extracting words from the lists\n",
    "    df = df.select(\n",
    "    explode(col(\"words\")).alias(\"words3\"))\n",
    "    \n",
    "    #every word to lower case\n",
    "    df = df.select(\n",
    "    lower(\n",
    "    col('words3')\n",
    "    ).alias('words44'))\n",
    "\n",
    "    #removing punctuation\n",
    "    punc = r\"[\\|\\-\\:\\!\\?\\.,]\"\n",
    "    https_rem = r\"(http|https)://[^\\s]*\"\n",
    "    \n",
    "    df = df.withColumn(\"words5\", regexp_replace(\"words44\", punc, \"\"))\n",
    "    df = df.withColumn(\"words4\", regexp_replace(\"words5\", https_rem, \"\"))\n",
    "\n",
    "    df = df.select(\n",
    "    regexp_extract(\n",
    "    col('words4'),  #cleaning words2 column\n",
    "    '[A-z]+',       #selecting all the words\n",
    "    0).alias('words5'))\n",
    "\n",
    "    # Removing the NULLs\n",
    "    df = df.where(\n",
    "        col(\"words5\") != \"\")\n",
    "    \n",
    "    #FIRST COUNT#\n",
    "    df_counted = df.groupBy(\n",
    "        col(\"words5\"),\n",
    "    ).count()\n",
    "\n",
    "    #RETAKING\n",
    "    df2 = df.select(\n",
    "        split(\n",
    "            col(\"words5\"),\n",
    "            \" \"\n",
    "        ).alias(\"word6\"))\n",
    "    \n",
    "    #removing stopwords - english \n",
    "    stopwords_remover2 = StopWordsRemover(inputCol=\"word6\", outputCol=\"words7\")\n",
    "    df2 = stopwords_remover2.transform(df2)\n",
    "    df2 = df2.drop(\"word6\")\n",
    "        \n",
    "    #removing nulls - step2\n",
    "    df2 = df2.select(\n",
    "        (col(\"words7\")[0]).alias(\"twitter_text_data_EN\"))\n",
    "\n",
    "    df2 = df2.where(\n",
    "    col(\"twitter_text_data_EN\") != \"null\")\n",
    "\n",
    "    df2 = df2.where(\n",
    "        col(\"twitter_text_data_EN\") != \"\")\n",
    "    \n",
    "    #FINAL COUNT#\n",
    "    df_counted2 = df2.groupby(\n",
    "    col(\"twitter_text_data_EN\")\n",
    "    ).count()\n",
    "\n",
    "    df_counted2 = df_counted2.orderBy(desc(\"count\"))\n",
    "    df_pandas = pd.DataFrame(df_counted2.collect(), columns=df_counted2.columns)\n",
    "    \n",
    "    return df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EN #\n",
    "#folder path\n",
    "folder_path = 'C:/Users/cedua/CDIA - PUCSP/PROJETO PySpark - SAVINO/Contador-de-palavras---PySpark/collecting_data/Twitter/en_data'\n",
    "\n",
    "#iterating the txt files only\n",
    "for txt_file in glob.glob(os.path.join(folder_path, '*.txt')):\n",
    "    df_pandas = clean_twitter_data_EN(txt_file)\n",
    "    df_pandas.to_csv(f'{txt_file[:-4]}.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT #\n",
    "#folder path\n",
    "folder_path = 'C:/Users/cedua/CDIA - PUCSP/PROJETO PySpark - SAVINO/Contador-de-palavras---PySpark/collecting_data/Twitter/pt_data'\n",
    "\n",
    "#iterating the txt files only\n",
    "for txt_file in glob.glob(os.path.join(folder_path, '*.txt')):\n",
    "    df_pandas = clean_twitter_data_PT(txt_file)\n",
    "    df_pandas.to_csv(f'{txt_file[:-4]}.csv', sep=';', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "twitter data PT\n",
    "- remover links\n",
    "- remover | , \\ , - , etc\n",
    "\n",
    "twitter data EN \n",
    "- remover links"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
